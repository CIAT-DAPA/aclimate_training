{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rBi6hviFCaRR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import calendar\n",
        "import numpy as np\n",
        "import random\n",
        "from statistics import mode\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U54c-KF3EiMn"
      },
      "source": [
        "hacer sÃ©ptimo mes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vZ08oIjlHnIR"
      },
      "outputs": [],
      "source": [
        "path_daily_data = \"C:/Users/lllanos/py_notebooks/example_workshop/ethiopia/inputs/climatePrediction/dailyData/\"\n",
        "path_probabilities = \"C:/Users/lllanos/py_notebooks/example_workshop/ethiopia/inputs/\"\n",
        "path_output = \"C:/Users/lllanos/py_notebooks/example_workshop/ethiopia/outputs/climatePrediction/resampling\"\n",
        "date_start = '2023-11-01' # Date of the first month of the season to forecast\n",
        "year_forecast = 2023 # Year of the first month of the season to forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SGxKppEs1zL0"
      },
      "outputs": [],
      "source": [
        "from shutil import rmtree\n",
        "if os.path.exists(path_output):\n",
        "    rmtree(path_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3ZoWQsLsXEC_"
      },
      "outputs": [],
      "source": [
        "def mdl_verification(daily_weather_data, seasonal_probabilities):\n",
        "    #################################\n",
        "    ####  Clima y Probabilidad   ####\n",
        "    #################################\n",
        "\n",
        "    clima = os.listdir(daily_weather_data)\n",
        "    clima = [file for file in clima if not file.endswith(\"_coords.csv\")]\n",
        "    clima = [file.split(\".csv\")[0] for file in clima]\n",
        "\n",
        "    prob = pd.read_csv(os.path.join(seasonal_probabilities , \"probabilities.csv\"))\n",
        "\n",
        "    ###############################################################\n",
        "    ### Tener en cuenta solo los Ids de clima en la base Prob   ###\n",
        "    ###############################################################\n",
        "\n",
        "    prob = prob[prob['id'].isin(clima)]\n",
        "\n",
        "    #######################\n",
        "    ### Revisemos clima ###\n",
        "    #######################\n",
        "\n",
        "    check_clm = []\n",
        "    for i in range(len(clima)):\n",
        "        df = pd.read_csv(os.path.join(daily_weather_data, f\"{clima[i]}.csv\"))\n",
        "\n",
        "        # 1. max de temp_max == min de temp_max\n",
        "        # 2. max de temp_min == min de temp_min\n",
        "        # 3. max de srad == min de srad\n",
        "\n",
        "        max_tmax = df['t_max'].max()\n",
        "        min_tmax = df['t_max'].min()\n",
        "\n",
        "        max_tmin = df['t_min'].max()\n",
        "        min_tmin = df['t_min'].min()\n",
        "\n",
        "        max_srad = df['sol_rad'].max()\n",
        "        min_srad = df['sol_rad'].min()\n",
        "\n",
        "        if max_tmax == min_tmax or max_tmin == min_tmin or max_srad == min_srad:\n",
        "            resultado = pd.DataFrame({'code': [clima[i]], 'value': [f\"tmax = {max_tmax}; tmin = {max_tmin}; srad = {max_srad}\"]})\n",
        "        else:\n",
        "            resultado = pd.DataFrame({'code': [clima[i]], 'value': [\"OK\"]})\n",
        "        check_clm.append(resultado)\n",
        "\n",
        "    df = pd.concat(check_clm)\n",
        "    df_1 = df[df['value'] == \"OK\"]\n",
        "    df_2 = df[df['value'] != \"OK\"]\n",
        "\n",
        "    code_ok = df_1\n",
        "    code_problema = df_2\n",
        "\n",
        "    ##################################\n",
        "    ####  Revisemos probabilidad  ####\n",
        "    ##################################\n",
        "\n",
        "    # 1. Probabilidades con cero categoria normal\n",
        "    # 2. Probabilidades sumen > 1.1\n",
        "    # 3. Probabilidades sumen <  0.9\n",
        "\n",
        "    prob['sum'] = prob['below'] + prob['normal'] + prob['above']\n",
        "    prob.loc[prob['normal'] == 0.00, 'normal'] = -1\n",
        "    prob.loc[prob['sum'] < 0.9, 'normal'] = -1\n",
        "    prob.loc[prob['sum'] > 1.1, 'normal'] = -1\n",
        "\n",
        "    df_1 = prob[prob['normal'] == -1]\n",
        "    df_2 = prob[(prob['normal'] >= 0) & (prob['normal'] <= 1)]\n",
        "\n",
        "    code_p_ok = df_2\n",
        "    code_p_malos = df_1\n",
        "\n",
        "\n",
        "    # Ids buenos: Datos de clima y probabilidades sin problemas\n",
        "    ids_buenos = code_p_ok['id'].tolist()\n",
        "\n",
        "    # Ids malos: clima malo - prob mala - outside\n",
        "    result_clima_prob_outside = list(set(clima) - set(code_p_ok['id']))\n",
        "\n",
        "    code_problema = pd.DataFrame({'ids':code_problema['code'].tolist(),\n",
        "                                  'descripcion': code_problema['value'].tolist()})\n",
        "    code_p_malos = pd.DataFrame({'ids': code_p_malos['id'].tolist(),\n",
        "                                 'descripcion': \"Problemas base de datos probabilidad\"})\n",
        "\n",
        "    result_clima_prob_outside = pd.DataFrame({'ids': result_clima_prob_outside,\n",
        "                                              'descripcion': \"La estacion esta fuera de area predictora\"})\n",
        "\n",
        "\n",
        "    ids_malos = pd.concat([code_problema, code_p_malos, result_clima_prob_outside])\n",
        "    ids_buenos = pd.DataFrame({'ids': ids_buenos})\n",
        "\n",
        "    ids_malos = ids_malos.replace(1, pd.NA).dropna()\n",
        "\n",
        "    result = {'ids_buenos': ids_buenos, 'ids_malos': ids_malos}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OFk7ievZ9EEx"
      },
      "outputs": [],
      "source": [
        "def preprocessing(prob_root,  ids):\n",
        "\n",
        "    \"\"\" Determine seasons of analysis according to the month of forecast in CPT\n",
        "\n",
        "    Args:\n",
        "\n",
        "    prob_root: str\n",
        "              The root of the probabilities file from CPT, with its name and extension.\n",
        "\n",
        "\n",
        "    ids: dict\n",
        "              Dictionary with a list of stations with problems and not to be analyzed, and\n",
        "              a list of stations without problems.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "      Dataframe\n",
        "          a dataframe with the original columns + name of season + start month of season +\n",
        "          end month of season\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Read the CPT probabilities file\n",
        "\n",
        "    proba = pd.read_csv(os.path.join(prob_root , \"probabilities.csv\"))\n",
        "\n",
        "    ids_x = ids['ids_buenos']\n",
        "    prob = proba[proba['id'].isin(ids_x['ids'])]\n",
        "    s = prob['season'].iloc[0]\n",
        "    forecast_period = \"tri\" if s.count(\"-\") > 1 else \"bi\"\n",
        "\n",
        "    # Check the period of forecast\n",
        "    if forecast_period == \"tri\":\n",
        "\n",
        "      # Create a list of month numbers from 1 to 12, followed by [1, 2] to create quarters\n",
        "      months_numbers =list(range(1,13)) + [1,2]\n",
        "\n",
        "      # Create a DataFrame representing periods of three consecutive months (with its numbers)\n",
        "      period= pd.DataFrame( [months_numbers[i:i+3] for i in range(0, len(months_numbers)-2)])\n",
        "      period.columns = ['Start', 'Central_month', 'End']\n",
        "\n",
        "\n",
        "      # Merge the prob DataFrame with the period DataFrame based on the 'month' and 'Central_month' columns\n",
        "      prob = prob.merge(period, left_on='month', right_on='Central_month')\n",
        "      prob.drop(['month','Central_month'], axis = 1, inplace = True )\n",
        "\n",
        "    else:\n",
        "      if forecast_period == \"bi\":\n",
        "\n",
        "        # Create a list of month numbers from 1 to 12\n",
        "        months_numbers = list(range(1,13))\n",
        "        months_numbers.append(1)\n",
        "\n",
        "\n",
        "        # Create a DataFrame representing periods of two consecutive months (with its numbers)\n",
        "        period = pd.DataFrame( [months_numbers[i:i+2] for i in range(0, len(months_numbers)-1)])\n",
        "        period.columns = ['Start', 'End']\n",
        "\n",
        "\n",
        "        # Merge the prob DataFrame with the period DataFrame based on the 'month' and 'Start' month columns\n",
        "        prob = prob.merge(period, left_on='month', right_on='Start')\n",
        "\n",
        "        # Merge the prob DataFrame with the period DataFrame based on the 'month' and 'End' month columns\n",
        "        # Join with prob_a\n",
        "        #prob = prob_a.append(prob.merge(period, left_on='month', right_on='End'))\n",
        "        prob.drop(['month'], axis = 1, inplace = True )\n",
        "\n",
        "    # Reshape the 'prob' DataFrame and put the 'below', 'normal' and 'above' probability categories in a column\n",
        "    prob = prob.melt(id_vars = ['year', 'id', 'predictand','season', 'Start','End'], var_name = 'Type', value_name = 'Prob')\n",
        "\n",
        "    #Return probability DataFrame\n",
        "    return prob, forecast_period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JPyJ9AoCVjqZ"
      },
      "outputs": [],
      "source": [
        "def forecast_station(station, prob, daily_data_root, output_root, year_forecast, forecast_period):\n",
        "\n",
        "    \"\"\" Generate  forecast scenaries\n",
        "\n",
        "    Args:\n",
        "\n",
        "    station: str\n",
        "            The id of th station\n",
        "\n",
        "      prob: DataFrame\n",
        "              The result of preprocessing function\n",
        "\n",
        "      daily_data_root: str\n",
        "              Where the climate data by station is located\n",
        "\n",
        "      output_root: str\n",
        "              Where outputs are going to be saved.\n",
        "\n",
        "      year_forecast: int\n",
        "              Year to forecast\n",
        "\n",
        "      forecast_period: str\n",
        "              'bi' if the period of CPT forecast is bimonthly.\n",
        "              'tri' if the period of CPT forecast is quarter.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "      Dataframe\n",
        "          a dataframe with climate daily data for every season and escenary id\n",
        "          a dataframe with years of escenary for every season\n",
        "\n",
        "    \"\"\"\n",
        "    # Create folders to save result\n",
        "    val_root = os.path.join(output_root, \"validation\")\n",
        "    if not os.path.exists(val_root):\n",
        "        os.makedirs(val_root)\n",
        "\n",
        "    # Read the climate data for the station\n",
        "    clim = pd.read_csv(os.path.join(daily_data_root ,f\"{station}.csv\"))\n",
        "\n",
        "    # Filter the probability data for the station\n",
        "    cpt_prob = prob[prob['id']==station]\n",
        "\n",
        "    if len(cpt_prob.index) == 0:\n",
        "      print('Station does not have probabilites')\n",
        "      base_years = 0\n",
        "      seasons_range = 0\n",
        "      p = {'id': [station],'issue': ['Station does not have probabilites']}\n",
        "      problem = pd.DataFrame(p)\n",
        "\n",
        "      return base_years, seasons_range,  problem\n",
        "\n",
        "    else:\n",
        "      # Get the season for the forecast\n",
        "      season = np.unique(cpt_prob['season'])\n",
        "      tri_seasons = ['Dec-Jan-Feb', 'Jan-Feb-Mar', 'Feb-Mar-Apr', 'Jan-Feb', 'Feb-Mar']\n",
        "\n",
        "      # Adjust the year if the forecast period is 'tri' if necessary\n",
        "      if  any(np.isin(season, tri_seasons)) :\n",
        "         year_forecast = year_forecast+1\n",
        "\n",
        "      # Check if year of forecast is a leap year for February\n",
        "      leap_forecast = (year_forecast%400 == 0) or (year_forecast%4==0 and year_forecast%100!=0)\n",
        "\n",
        "      # Filter the February data for leap years\n",
        "      clim_feb = clim.loc[clim['month'] == 2]\n",
        "      clim_feb['leap'] = [True if (year%400 == 0) or (year%4==0 and year%100!=0) else False for year in clim_feb['year']]\n",
        "\n",
        "      # Standardize february months by year according to year of forecat\n",
        "      february = pd.DataFrame()\n",
        "      for i in np.unique(clim_feb['year']):\n",
        "        year_data =  clim_feb.loc[clim_feb['year']==i,:]\n",
        "        year = year_data.loc[:,'leap']\n",
        "\n",
        "        # If year of forecast is a leap year and a year in climate data is not, then add one day to february in climate data\n",
        "        if leap_forecast == True and year.iloc[0] == False:\n",
        "          year_data = pd.concat([year_data, year_data.sample(1)], ignore_index=True)\n",
        "          year_data.iloc[-1,0] = 29\n",
        "        else:\n",
        "\n",
        "          # If year of forecast is not a leap year and a year in climate data is, then remove one day to february in climate data\n",
        "          if leap_forecast == False and year.iloc[0] == True:\n",
        "            year_data =  year_data.iloc[:-1]\n",
        "          else:\n",
        "\n",
        "            # If both year of forecast and year in climate data are leap years or not, then keep climate data the same\n",
        "            year_data = year_data\n",
        "        february = pd.concat([february, year_data])\n",
        "\n",
        "\n",
        "      # Concat standardized february data with the rest of climate data\n",
        "      data = february.drop(['leap'], axis = 1 )\n",
        "      data = pd.concat([data,clim.loc[clim['month'] != 2]]).sort_values(['year','month'])\n",
        "\n",
        "      # Start the resampling process for every season of analysis in CPT probabilities file\n",
        "\n",
        "      base_years =  pd.DataFrame() # List to store years of sample for each season\n",
        "      seasons_range = pd.DataFrame() # List to store climate data in the years of sample for each season\n",
        "\n",
        "      for season in  list(np.unique(cpt_prob['season'])):\n",
        "\n",
        "        # Select the probabilities for the season\n",
        "        x = cpt_prob[cpt_prob['season'] == season]\n",
        "\n",
        "\n",
        "        predictand = cpt_prob['predictand'].iloc[0]\n",
        "\n",
        "\n",
        "      # Compute total precipitation for each year in the climate data range selected\n",
        "        new_data = data[['year',predictand]].groupby(['year']).sum().reset_index()\n",
        "\n",
        "        data['season'] = season\n",
        "\n",
        "\n",
        "      # Calculate quantiles to determine precipitation conditions for every year in climate data selected\n",
        "        cuantiles = list(np.quantile(new_data['prec'], [.33,.66]))\n",
        "        new_data['condition'] =  'NA'\n",
        "        new_data.loc[new_data[predictand]<= cuantiles[0], 'condition'] = 'below'\n",
        "        new_data.loc[new_data[predictand]>= cuantiles[1], 'condition'] =  'above'\n",
        "        new_data.loc[(new_data[predictand]> cuantiles[0]) & (new_data[predictand]< cuantiles[1]), 'condition'] =  'normal'\n",
        "\n",
        "      # Sample 100 records in probability file of season based on probability from CPT as weights\n",
        "        muestras = x[['Start', 'End', 'Type', 'Prob']].sample(100, replace = True, weights=x['Prob'])\n",
        "        muestras = muestras.set_index(pd.Index(list(range(0,100))))\n",
        "\n",
        "      # Randomly get one year from the total precipitation data based on precipitation conditions selected in the 100 data sample.\n",
        "        muestras_by_type = []\n",
        "        for i in muestras.index:\n",
        "          m = new_data.loc[new_data['condition'] == muestras['Type'].iloc[i]].sample(1)\n",
        "\n",
        "          if any(m['year'] == max(new_data['year'])):\n",
        "            b = new_data.loc[new_data['condition'] == muestras['Type'].iloc[i]]\n",
        "            m = b[b['year'] != max(new_data['year'])].sample(1)\n",
        "          else:\n",
        "            m = m\n",
        "\n",
        "          muestras_by_type.append(m)\n",
        "\n",
        "        # Join the 100 samples and add sample id\n",
        "        muestras_by_type = pd.concat(muestras_by_type).reset_index()\n",
        "        muestras_by_type['index'] = muestras.index\n",
        "        #muestras_by_type = muestras_by_type.set_index(pd.Index(list(range(0,100))))\n",
        "\n",
        "\n",
        "        # Rename year column with season name\n",
        "        muestras_by_type = muestras_by_type.rename(columns = {'year':season})\n",
        "\n",
        "        #Set the sample years as list and sort\n",
        "        years = list(muestras_by_type[season])\n",
        "        years.sort()\n",
        "\n",
        "\n",
        "        if season == 'Nov-Dec-Jan':\n",
        "          # If season is November-December-January\n",
        "\n",
        "          # Calculate the next year of the year sample and assign the same sample id\n",
        "          muestras_by_type['plus'] = list(map(lambda x: x + 1, muestras_by_type[season]))\n",
        "\n",
        "\n",
        "          years_plus = list(map(lambda x: x + 1, years))\n",
        "          years_plus.sort()\n",
        "\n",
        "          # Filter the climate data of the last two months of the years in the sample and get the sample id\n",
        "          merge_a =  data[data['year'].isin(years)]\n",
        "          merge_a = merge_a[merge_a['month'].isin([11,12])]\n",
        "          merge_a = pd.merge(merge_a, muestras_by_type[['index', season]], left_on = 'year', right_on = season)\n",
        "          merge_a.drop(season, axis = 1,inplace = True)\n",
        "\n",
        "          # Filter the climate data of the first month in the next year of the years in sample and get the sample id\n",
        "          merge_b = data[data['year'].isin(years_plus)]\n",
        "          merge_b = merge_b[merge_b['month'] == 1]\n",
        "          merge_b = pd.merge(merge_b, muestras_by_type[['index', 'plus']], left_on = 'year', right_on = 'plus')\n",
        "          merge_b.drop('plus', axis = 1,inplace = True)\n",
        "\n",
        "          # Merge the climate data filtered\n",
        "          merge = pd.concat([merge_a, merge_b])\n",
        "\n",
        "\n",
        "        else:\n",
        "          if season == 'Dec-Jan-Feb':\n",
        "            # If season is December-January-February\n",
        "\n",
        "\n",
        "            # Calculate the next year of the year sample and assign the same sample id\n",
        "            muestras_by_type['plus'] = list(map(lambda x: x + 1, muestras_by_type[season]))\n",
        "\n",
        "            years_plus = list(map(lambda x: x + 1, years))\n",
        "            years_plus.sort()\n",
        "\n",
        "            # Filter the climate data of the last month of the years in the sample and get the sample id\n",
        "\n",
        "            merge_a = data[data['year'].isin(years)]\n",
        "            merge_a = merge_a[merge_a['month'] == 12]\n",
        "            merge_a = pd.merge(merge_a, muestras_by_type[['index', season]], left_on = 'year', right_on = season)\n",
        "            merge_a = merge_a.drop(columns = [season])\n",
        "\n",
        "            # Filter the climate data of the first two months in the next year of the years in sample and get the sample id\n",
        "\n",
        "            merge_b = data[data['year'].isin(years_plus)]\n",
        "            merge_b = merge_b[merge_b['month'].isin([1,2])]\n",
        "            merge_b = pd.merge(merge_b, muestras_by_type[['index', 'plus']], left_on = 'year', right_on = 'plus')\n",
        "            merge_b = merge_b.drop(columns = ['plus'])\n",
        "\n",
        "            # Merge filtered data\n",
        "            merge = pd.concat([merge_a, merge_b])\n",
        "\n",
        "\n",
        "          else:\n",
        "            if season == 'Dec-Jan':\n",
        "\n",
        "                    # Calculate the next year of the year sample and assign the same sample id\n",
        "                    muestras_by_type['plus'] = list(map(lambda x: x + 1, muestras_by_type[season]))\n",
        "\n",
        "                    years_plus = list(map(lambda x: x + 1, years))\n",
        "                    years_plus.sort()\n",
        "\n",
        "                    # Filter the climate data of the last month of the years in the sample and get the sample id\n",
        "\n",
        "                    merge_a = data[data['year'].isin(years)]\n",
        "                    merge_a = merge_a[merge_a['month'] == 12]\n",
        "                    merge_a = pd.merge(merge_a, muestras_by_type[['index', season]], left_on = 'year', right_on = season)\n",
        "                    merge_a = merge_a.drop(columns = [season])\n",
        "\n",
        "                    # Filter the climate data of the first two months in the next year of the years in sample and get the sample id\n",
        "\n",
        "                    merge_b = data[data['year'].isin(years_plus)]\n",
        "                    merge_b = merge_b[merge_b['month'] == 1]\n",
        "                    merge_b = pd.merge(merge_b, muestras_by_type[['index', 'plus']], left_on = 'year', right_on = 'plus')\n",
        "                    merge_b = merge_b.drop(columns = ['plus'])\n",
        "\n",
        "                    # Merge filtered data\n",
        "                    merge = pd.concat([merge_a, merge_b])\n",
        "\n",
        "            else:\n",
        "                    # If season is another, filter climate data of the years in sample and get the sample id\n",
        "\n",
        "                    merge = data.loc[data['year'].isin(years)]\n",
        "                    merge = merge.loc[(merge['month'] >= x['Start'].iloc[0]) & (merge['month'] <= x['End'].iloc[0])]\n",
        "                    merge = pd.merge(merge,muestras_by_type[['index',season]],left_on = 'year', right_on = season)\n",
        "                    merge = merge.drop(columns = [season])\n",
        "\n",
        "\n",
        "        # Join seasons samples by column by sample id\n",
        "        base_years = pd.concat([base_years, muestras_by_type[['index',season]]], axis = 1,ignore_index=True)\n",
        "\n",
        "        # Join climate data filtered for the seasons\n",
        "        seasons_range = pd.concat([seasons_range, merge])\n",
        "\n",
        "      seasons_range = seasons_range.rename(columns = {'index': 'id'})\n",
        "\n",
        "      if (forecast_period == 'tri') and (len(list(np.unique(cpt_prob['season']))) == 2):\n",
        "\n",
        "            s = list(np.unique(cpt_prob['season']))\n",
        "            base_years = base_years.iloc[:,[0,1,3] ]\n",
        "            base_years = base_years.rename(columns={0: 'id',1: s[0], 3: s[1]})\n",
        "            base_years['id'] = base_years['id'] + 1\n",
        "            seasons_range['id'] = seasons_range['id']+1\n",
        "            seasons_range = seasons_range.sort_values(by=['year', 'month'], ascending=True)\n",
        "            base_years.to_csv(os.path.join(val_root,  f\"{station}_Escenario_A.csv\"), index = False)\n",
        "\n",
        "\n",
        "            #Return climate data filtered with sample id\n",
        "            return base_years, seasons_range\n",
        "\n",
        "      else:\n",
        "          if (forecast_period == 'bi') and (len(list(np.unique(cpt_prob['season']))) == 3) :\n",
        "\n",
        "            s = list(np.unique(cpt_prob['season']))\n",
        "            base_years = base_years.iloc[:,[0,1,3,5] ]\n",
        "            base_years = base_years.rename(columns={0: 'id',1: s[0], 3: s[1], 5: s[2]})\n",
        "            base_years['id'] = base_years['id'] + 1\n",
        "            seasons_range['id'] = seasons_range['id']+1\n",
        "            seasons_range = seasons_range.sort_values(by=['year', 'month'], ascending=True)\n",
        "            base_years.to_csv(os.path.join(val_root,  f\"{station}_Escenario_A.csv\"), index = False)\n",
        "\n",
        "\n",
        "            #Return climate data filtered with sample id\n",
        "            return base_years, seasons_range\n",
        "\n",
        "          else:\n",
        "\n",
        "            print('Station does not have all the seasons availables')\n",
        "\n",
        "            s = list(np.unique(cpt_prob['season']))\n",
        "            if len(base_years.columns) == 2:\n",
        "              base_years = base_years.iloc[:,[0,1] ]\n",
        "              base_years = base_years.rename(columns={0: 'id',1: s[0]})\n",
        "            else:\n",
        "              if len(base_years.columns == 4):\n",
        "                base_years = base_years.rename(columns={0: 'id',1: s[0], 3: s[1]})\n",
        "              else:\n",
        "                base_years = base_years.rename(columns={0: 'id',1: s[0]})\n",
        "\n",
        "            base_years['id'] = base_years['id'] + 1\n",
        "            seasons_range['id'] = seasons_range['id']+1\n",
        "\n",
        "\n",
        "            p = {'id': [station],'issue': ['Station does not have all the seasons availables'], 'Seasons available': \", \".join([str(item) for item in s])}\n",
        "            problem = pd.DataFrame(p)\n",
        "            print(problem)\n",
        "            base_years.to_csv(os.path.join(val_root, f\"{station}_Escenario_A.csv\"), index = False)\n",
        "\n",
        "            #Return climate data filtered with sample id\n",
        "            return base_years, seasons_range, problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BvAWldFHqldp"
      },
      "outputs": [],
      "source": [
        "def add_year(year_forecast, m, date_start):\n",
        "  date_start = datetime.strptime(date_start, \"%Y-%m-%d\") #convertir a fecha\n",
        "  if m < date_start.month:\n",
        "    a = year_forecast + 1\n",
        "  else:\n",
        "    a = year_forecast\n",
        "\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZyRZUdHtCtrD"
      },
      "outputs": [],
      "source": [
        "def save_forecast(station, output_root, year_forecast, seasons_range, base_years, date_start):\n",
        "\n",
        "\n",
        "    if isinstance(base_years, pd.DataFrame):\n",
        "    # Set the output root based on forecast period\n",
        "      output_estacion = os.path.join(output_root, station)\n",
        "      if not os.path.exists(output_estacion):\n",
        "          os.makedirs(output_estacion)\n",
        "          print(\"Path created for the station: {}\".format(station))\n",
        "\n",
        "      output_summary = os.path.join(output_root, \"summary\")\n",
        "      if not os.path.exists(output_summary):\n",
        "          os.makedirs(output_summary)\n",
        "\n",
        "      escenarios = []\n",
        "      IDs= list(np.unique(seasons_range['id']))\n",
        "      seasons =  list(np.unique(seasons_range['season']))\n",
        "      year_forecast = int(year_forecast)\n",
        "\n",
        "      for i in range(len(IDs)):\n",
        "        \n",
        "\n",
        "        df = seasons_range[(seasons_range['id'] == IDs[i])]\n",
        "\n",
        "        df = df.reset_index()\n",
        "        df = df.drop(columns = ['year'])\n",
        "        for j in list(range(len(df))):\n",
        "\n",
        "            df.loc[j, 'year'] = add_year(year_forecast, df.loc[j, 'month'], date_start)\n",
        "\n",
        "        df = df.drop(['index','id', 'season'], axis = 1)\n",
        "        df['year'] = df['year'].astype('int')\n",
        "\n",
        "        escenarios.append(df)\n",
        "        df.to_csv(os.path.join(output_estacion ,f\"{station}_escenario_{str(i+1)}.csv\"), index=False)\n",
        "\n",
        "      print(\"Escenaries saved in {}\".format(output_estacion))\n",
        "\n",
        "      # Calculate maximum and minimum of escenaries by date and save\n",
        "      df = pd.concat(escenarios)\n",
        "      columns = list(df.columns)\n",
        "      columns.remove('year')\n",
        "      new_columns = columns[:2] + ['year'] + columns[2:]\n",
        "      df = df[new_columns]\n",
        "\n",
        "\n",
        "      df.groupby(['year', 'month', 'day']).max().reset_index().sort_values(['month', 'day'], ascending = True).to_csv(os.path.join(output_summary, f\"{station}_escenario_max.csv\"), index=False)\n",
        "      df.groupby(['year', 'month', 'day']).min().reset_index().sort_values(['month', 'day'], ascending = True).to_csv(os.path.join(output_summary, f\"{station}_escenario_min.csv\"), index=False)\n",
        "      print(\"Minimum and Maximum of escenaries saved in {}\".format(output_summary))\n",
        "\n",
        "      vars = df.columns\n",
        "      vars = [item for item in vars if item != \"year\"]\n",
        "      vars = [item for item in vars if item != \"month\"]\n",
        "      vars = [item for item in vars if item != \"day\"]\n",
        "\n",
        "      for i in range(len(vars)):\n",
        "         print(df.groupby(['year', 'month'])[vars[i]].mean().reset_index().rename(columns = {vars[i]: 'avg'}).sort_values(['year', 'month'], ascending = True))\n",
        "\n",
        "         df.groupby(['year', 'month'])[vars[i]].max().reset_index().rename(columns = {vars[i]: 'max'}).sort_values(['year', 'month'], ascending = True).to_csv(os.path.join(output_summary, f\"{station}_{vars[i]}_max.csv\"), index=False)\n",
        "         df.groupby(['year', 'month'])[vars[i]].min().reset_index().rename(columns = {vars[i]: 'min'}).sort_values(['year', 'month'], ascending = True).to_csv(os.path.join(output_summary, f\"{station}_{vars[i]}_min.csv\"), index=False)\n",
        "         df.groupby(['year', 'month'])[vars[i]].mean().reset_index().rename(columns = {vars[i]: 'avg'}).sort_values(['year', 'month'], ascending = True).to_csv(os.path.join(output_summary, f\"{station}_{vars[i]}_avg.csv\"), index=False)\n",
        "\n",
        "\n",
        "      print(\"Minimum, Maximum and Average of variables by escenary is saved in {}\".format(output_summary))\n",
        "      return df\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "      return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H-LbkdgArgHu"
      },
      "outputs": [],
      "source": [
        "def resampling_master(station, verifica,input_root, climate_data_root,  output_root, year_forecast, date_start):\n",
        "\n",
        "    if not os.path.exists(output_root):\n",
        "        os.makedirs(output_root)\n",
        "        print(\"Path created for outputs\")\n",
        "\n",
        "    print(\"Processing station: \" + str(station))\n",
        "\n",
        "    print(\"Reading the probability file and getting the forecast seasons\")\n",
        "    prob_normalized = preprocessing(input_root, verifica)\n",
        "\n",
        "\n",
        "    print(\"Resampling and creating the forecast scenaries\")\n",
        "    resampling_forecast = forecast_station(station = station,\n",
        "                                           prob = prob_normalized[0],\n",
        "                                           daily_data_root = climate_data_root,\n",
        "                                           output_root = output_root,\n",
        "                                           year_forecast = year_forecast,\n",
        "                                           forecast_period= prob_normalized[1])\n",
        "\n",
        "\n",
        "    print(\"Saving escenaries and a summary\")\n",
        "    save_forecast(station = station,\n",
        "                  output_root = output_root,\n",
        "                  year_forecast = year_forecast,\n",
        "                  base_years = resampling_forecast[0],\n",
        "                  seasons_range = resampling_forecast[1],\n",
        "                  date_start = date_start)\n",
        "\n",
        "    if len(resampling_forecast) == 3:\n",
        "        oth =os.path.join(output_root, \"issues.csv\")\n",
        "        resampling_forecast[2].to_csv(oth, mode='a', index=False, header=not os.path.exists(oth))\n",
        "\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv5Lbuoz-W1l"
      },
      "source": [
        "To run just one station:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XULnqDnMqIMH"
      },
      "outputs": [],
      "source": [
        "estaciones = os.listdir(path_daily_data)\n",
        "n = [i for i in estaciones if not  i.endswith(\"_coords.csv\") ]\n",
        "n = [i.replace(\".csv\",\"\") for i in n]\n",
        "\n",
        "verifica = mdl_verification(path_daily_data, path_probabilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oGPaohN67bmP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path created for outputs\n",
            "Processing station: woyalita\n",
            "Reading the probability file and getting the forecast seasons\n",
            "Resampling and creating the forecast scenaries\n",
            "Saving escenaries and a summary\n",
            "Path created for the station: woyalita\n",
            "Escenaries saved in C:/Users/lllanos/py_notebooks/example_workshop/ethiopia/outputs/climatePrediction/resampling\\woyalita\n",
            "Minimum and Maximum of escenaries saved in C:/Users/lllanos/py_notebooks/example_workshop/ethiopia/outputs/climatePrediction/resampling\\summary\n",
            "   year  month        avg\n",
            "0  2023     11  23.395150\n",
            "1  2023     12  24.200668\n",
            "2  2024      1  24.846794\n",
            "3  2024      2  25.629779\n",
            "4  2024      3  25.331013\n",
            "5  2024      4  23.782743\n",
            "   year  month        avg\n",
            "0  2023     11  13.237603\n",
            "1  2023     12  13.244232\n",
            "2  2024      1  13.791277\n",
            "3  2024      2  14.225431\n",
            "4  2024      3  14.779426\n",
            "5  2024      4  14.588327\n",
            "   year  month       avg\n",
            "0  2023     11  1.954133\n",
            "1  2023     12  0.683058\n",
            "2  2024      1  0.962981\n",
            "3  2024      2  1.467224\n",
            "4  2024      3  3.012897\n",
            "5  2024      4  5.282853\n",
            "   year  month        avg\n",
            "0  2023     11  21.634730\n",
            "1  2023     12  21.757484\n",
            "2  2024      1  22.071635\n",
            "3  2024      2  23.175472\n",
            "4  2024      3  22.670558\n",
            "5  2024      4  20.975717\n",
            "Minimum, Maximum and Average of variables by escenary is saved in C:/Users/lllanos/py_notebooks/example_workshop/ethiopia/outputs/climatePrediction/resampling\\summary\n"
          ]
        }
      ],
      "source": [
        "resampling_master(station =n[0],\n",
        "                  input_root =  path_probabilities,\n",
        "                  climate_data_root = path_daily_data,\n",
        "                  output_root = path_output,\n",
        "                  verifica = verifica,\n",
        "                  year_forecast = year_forecast,\n",
        "                  date_start = date_start )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
